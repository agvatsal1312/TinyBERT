{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["W-4v85Ezl-De","3GpNNBp8pOfJ","0WAzPHY96CgV","ozpVZpdn6OQy","4iSoClBHlhoh","SO71Zdkklnph","6ETxlZ_Bl5Og","ez_YImKPnxmg","a5wyOM7un7sv","fm30zBlwm8x6","Mx3c4KfTvs5Q","CNT5Omjmvzek","ZCKFGIhypAm3","fCM_P8XXgGqA","sREvEin2voei"],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12439449,"sourceType":"datasetVersion","datasetId":7842060}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Configuration","metadata":{"id":"W-4v85Ezl-De"}},{"cell_type":"code","source":"!pip install -U datasets huggingface_hub fsspec","metadata":{"id":"CUBZQUpgSLip","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:42:08.742418Z","iopub.status.idle":"2025-07-11T09:42:08.742770Z","shell.execute_reply.started":"2025-07-11T09:42:08.742580Z","shell.execute_reply":"2025-07-11T09:42:08.742598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#config\nvocab_size=30000\nspecial_tokens=[\"CLS\",\"SEP\",\"UNK\",\"PAD\"]\nn_segments=2\nmax_len=350\nembedd_dim=768\nn_layers=8\nattn_heads=12\ndropout=0.1\nd_ff=1600\n\n","metadata":{"id":"8i5P9oPWW7rw","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:01.502552Z","iopub.execute_input":"2025-07-11T09:43:01.503026Z","iopub.status.idle":"2025-07-11T09:43:01.506852Z","shell.execute_reply.started":"2025-07-11T09:43:01.503002Z","shell.execute_reply":"2025-07-11T09:43:01.506041Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Embeddings","metadata":{"id":"3GpNNBp8pOfJ"}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport math\nclass InputEmbedding(nn.Module):\n  def __init__(self,vocab_size:int,d_model:int)->None:\n    super().__init__()\n    self.d_model=d_model\n    self.vocab_size=vocab_size\n    self.embedd=nn.Embedding(vocab_size,self.d_model)\n  def forward(self,x):\n  #(batch,seq_len)-->(batch,seq_len,d_model)\n    return self.embedd(x)*math.sqrt(self.d_model)\n\nclass SegmentEmbedding(nn.Module):\n  def __init__(self,n_segments:int,d_model:int)->None:\n    super().__init__()\n    self.segment_embedd=nn.Embedding(n_segments,d_model)\n  def forward(self,x):\n    return self.segment_embedd(x)\n\nclass PositionalEmbedding(nn.Module):\n  def __init__(self,seq_len:int,d_model:int,dropout:float)->None:\n    super().__init__()\n    self.seq_len=seq_len\n    self.d_model=d_model\n    self.drop=nn.Dropout(dropout)\n    pe=torch.zeros(seq_len,d_model)\n    position=torch.arange(0,seq_len,dtype=torch.float).unsqueeze(1)\n    div_term=torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000.0)/d_model))\n    pe[:,0::2]=torch.sin(position*div_term)\n    pe[:,1::2]=torch.cos(position*div_term)\n\n    pe=pe.unsqueeze(0)  #adding batch dim\n    self.register_buffer(\"pe\",pe)\n  def forward(self,x):\n    x=x+ self.pe[:,:x.shape[1],:].detach()\n    return self.drop(x)\n\n","metadata":{"id":"zbjBtubDi1sN","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:02.300929Z","iopub.execute_input":"2025-07-11T09:43:02.301430Z","iopub.status.idle":"2025-07-11T09:43:02.310020Z","shell.execute_reply.started":"2025-07-11T09:43:02.301407Z","shell.execute_reply":"2025-07-11T09:43:02.309153Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class full_embeddings(nn.Module):\n  def __init__(self,src_emb:InputEmbedding,pe_emb:PositionalEmbedding,se_emb:SegmentEmbedding,sep_input_id):\n    super().__init__()\n    self.src_emb=src_emb\n    self.pe_emb=pe_emb\n    self.se_emb=se_emb\n    self.sep_input_id=sep_input_id\n\n\n  def forward(self,input_ids,segment_ids):\n\n    x=self.pe_emb(self.src_emb(input_ids)+self.se_emb(segment_ids))\n    return x\n","metadata":{"id":"UO3BD2ju5dde","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:02.790289Z","iopub.execute_input":"2025-07-11T09:43:02.790531Z","iopub.status.idle":"2025-07-11T09:43:02.795078Z","shell.execute_reply.started":"2025-07-11T09:43:02.790511Z","shell.execute_reply":"2025-07-11T09:43:02.794506Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Normalization block,residual block,feedforward block","metadata":{"id":"0WAzPHY96CgV"}},{"cell_type":"code","source":"class LayerNormalization(nn.Module):\n  def __init__(self,d_model, eps:float=1e-6)->None:\n    super().__init__()\n    self.eps=eps\n    self.alpha=nn.Parameter(torch.ones(d_model))\n    self.bias=nn.Parameter(torch.zeros(d_model))\n  def forward(self,x):\n    mean=x.mean(dim=-1,keepdim=True)\n    std=x.std(dim=-1,keepdim=True)\n\n    return self.alpha*(x-mean)/(std+self.eps) +self.bias\n\n\nclass FeedForwardNetwork(nn.Module):\n  def __init__(self,d_model:int,d_ff:int,dropout:float)->None:\n    super().__init__()\n    self.linear_1=nn.Linear(d_model,d_ff)\n    self.linear_2=nn.Linear(d_ff,d_model)\n    self.drop=nn.Dropout(dropout)\n    # self.relu=nn.ReLU()\n  def forward(self,x):\n    x=torch.relu(self.linear_1(x))\n    x=self.drop(x)\n    return self.linear_2(x)\n\n\nclass ResidualConnection(nn.Module):\n  def __init__(self,d_model,drop:float)->None:\n    super().__init__()\n    self.norm=LayerNormalization(d_model)\n    self.drop=nn.Dropout(drop)\n  def forward(self,x,sublayer):\n    return x+self.drop(sublayer(self.norm(x)))\n\n","metadata":{"id":"bIre-xRfpXUI","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:03.703604Z","iopub.execute_input":"2025-07-11T09:43:03.704280Z","iopub.status.idle":"2025-07-11T09:43:03.710366Z","shell.execute_reply.started":"2025-07-11T09:43:03.704259Z","shell.execute_reply":"2025-07-11T09:43:03.709775Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Attention Block","metadata":{"id":"ozpVZpdn6OQy"}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n  def __init__(self,d_model:int,heads:int,dropout:float):\n    super().__init__()\n    self.heads=heads\n    assert d_model % heads==0, \"d_model not divisible by heads\"\n    self.d_k=d_model//heads\n    self.heads=heads\n    self.q=nn.Linear(d_model,d_model)\n    self.k=nn.Linear(d_model,d_model)\n    self.v=nn.Linear(d_model,d_model)\n    self.w_o=nn.Linear(d_model,d_model)\n    self.dropout=nn.Dropout(dropout)\n\n  def attention(self,q,k,v,mask,dropout):\n    d_k=q.shape[-1]\n    attention_score=q@k.transpose(-2,-1)/math.sqrt(d_k)\n    if mask is not None:\n      mask = mask.unsqueeze(1).unsqueeze(2)\n      # attention_score=attention_score.masked_fill(mask==0,-1e9)\n      mask = mask.to(dtype=torch.bool, device=attention_score.device)\n      min_val = torch.finfo(attention_score.dtype).min\n      attention_score = attention_score.masked_fill(mask == 0, min_val)\n    attention_score=torch.softmax(attention_score,dim=-1)\n    if dropout is not None:\n      attention_score=dropout(attention_score)\n    return attention_score@v, attention_score\n\n  def forward(self,q,k,v,mask):\n    q=self.q(q)\n    k=self.k(k)\n    v=self.v(v)\n\n    q=q.view(q.shape[0],q.shape[1],self.heads,self.d_k).transpose(1,2)\n    k=k.view(k.shape[0],k.shape[1],self.heads,self.d_k).transpose(1,2)\n    v=v.view(v.shape[0],v.shape[1],self.heads,self.d_k).transpose(1,2)\n\n    x,attention_score=self.attention(q,k,v,mask,self.dropout)\n    x=x.transpose(1,2).contiguous().view(x.shape[0],-1,self.heads*self.d_k)\n    x=self.w_o(x)\n    return x\n\n","metadata":{"id":"H-Va0JLv6RSl","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:04.122319Z","iopub.execute_input":"2025-07-11T09:43:04.122569Z","iopub.status.idle":"2025-07-11T09:43:04.130364Z","shell.execute_reply.started":"2025-07-11T09:43:04.122552Z","shell.execute_reply":"2025-07-11T09:43:04.129792Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Encoder","metadata":{"id":"4iSoClBHlhoh"}},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n  def __init__(self,d_model,d_ff,dropout,heads):\n    super().__init__()\n    self.feedfwd=FeedForwardNetwork(d_model,d_ff,dropout)\n\n    self.residual=nn.ModuleList([ResidualConnection(d_model,dropout),ResidualConnection(d_model,dropout)])\n    self.attention=MultiHeadAttention(d_model,heads,dropout)\n  def forward(self, x,mask):\n    x=self.residual[0](x,lambda x: self.attention(x,x,x,mask))\n    x=self.residual[1](x,self.feedfwd)\n    return x\n\n\nclass Encoder(nn.Module):\n  def __init__(self,d_model,d_ff,dropout,heads,n_layers):\n    super().__init__()\n    self.encoders=nn.ModuleList([EncoderBlock(d_model,d_ff,dropout,heads) for _ in range(n_layers)])\n  def forward(self,x,mask):\n    for layer in self.encoders:\n      x=layer(x,mask)\n    return x\n\n","metadata":{"id":"9McmRN9MmWmF","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:10.751045Z","iopub.execute_input":"2025-07-11T09:43:10.751595Z","iopub.status.idle":"2025-07-11T09:43:10.757620Z","shell.execute_reply.started":"2025-07-11T09:43:10.751574Z","shell.execute_reply":"2025-07-11T09:43:10.756874Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Classifier","metadata":{"id":"SO71Zdkklnph"}},{"cell_type":"code","source":"class Classifier(nn.Module):\n  def __init__(self,d_model:int,d_ff:int,dropout:float,output_size:int=3)->None:\n    super().__init__()\n    self.classifier=nn.Sequential(nn.Linear(d_model,d_ff),\n                                  nn.ReLU(),\n                                  nn.Dropout(dropout),\n                                  nn.Linear(d_ff,1024),\n                                  nn.ReLU(),\n                                  nn.Dropout(dropout),\n                                  nn.Linear(1024,output_size),\n                                  # nn.Sigmoid()\n    )\n  def forward(self,x):\n    return self.classifier(x)\n\n","metadata":{"id":"aRzaJKUcu1OY","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:13.218266Z","iopub.execute_input":"2025-07-11T09:43:13.218894Z","iopub.status.idle":"2025-07-11T09:43:13.223588Z","shell.execute_reply.started":"2025-07-11T09:43:13.218868Z","shell.execute_reply":"2025-07-11T09:43:13.223015Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Transformer","metadata":{"id":"6ETxlZ_Bl5Og"}},{"cell_type":"code","source":"class Transformer(nn.Module):\n  def __init__(self,encoder:Encoder,embeddings:full_embeddings)->None:\n    super().__init__()\n    self.encoder=encoder\n    # self.classifier=classifier\n    self.emb=embeddings\n  def forward(self, x,segment_ids,mask):\n    # B,S,E=x.shape\n    x=self.emb(x,segment_ids)\n    output=self.encoder(x,mask)\n    cls=output[:,0,:]\n    cls=cls.squeeze(1)\n    # logits=self.classifier(cls)\n    return cls\ndef build_transformer(vocab_size:int,n_segments:int,embedd_dim:int,max_len:int,n_layers:int,attn_heads:int,dropout:float,d_ff:int,c_d_ff:int,nli_pretrain:bool,sep_input_id:int=2)-> Transformer:\n  input_emb=InputEmbedding(vocab_size,embedd_dim)\n  seg_emb=SegmentEmbedding(n_segments,embedd_dim)\n  pe_emb=PositionalEmbedding(max_len,embedd_dim,dropout)\n\n  full_emb=full_embeddings(input_emb,pe_emb,seg_emb,sep_input_id)\n\n  encoder=Encoder(embedd_dim,d_ff,dropout,attn_heads,n_layers)\n\n  transformer=Transformer(encoder,full_emb)\n\n  for p in transformer.parameters():\n    if p.dim()>1:\n      nn.init.xavier_uniform_(p)\n  if nli_pretrain:\n    classifier=Classifier(embedd_dim,d_ff,dropout)\n    for p in classifier.parameters():\n      if p.dim()>1:\n        nn.init.xavier_uniform_(p)\n    return transformer, classifier\n\n\n  return transformer\n","metadata":{"id":"sRMM8S-wHsdW","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:15.795647Z","iopub.execute_input":"2025-07-11T09:43:15.796205Z","iopub.status.idle":"2025-07-11T09:43:15.802623Z","shell.execute_reply.started":"2025-07-11T09:43:15.796181Z","shell.execute_reply":"2025-07-11T09:43:15.801932Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Tokenizer","metadata":{"id":"ez_YImKPnxmg"}},{"cell_type":"code","source":"from tokenizers import Tokenizer\nfrom tokenizers.models import WordPiece\ntokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n\nfrom tokenizers.trainers import WordPieceTrainer\ntrainer = WordPieceTrainer(vocab_size=vocab_size,special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n\nfrom tokenizers.pre_tokenizers import Whitespace\ntokenizer.pre_tokenizer = Whitespace()\n\n# files = [f\"data/wikitext-103-raw/wiki.{split}.raw\" for split in [\"test\", \"train\", \"valid\"]]\n# files=[f\"/content/train-00000-of-00002.raw\",\"/content/train-00001-of-00002.raw\"]\n# tokenizer.train(files, trainer)\n","metadata":{"id":"abLXqKPyuMEI","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:19.220922Z","iopub.execute_input":"2025-07-11T09:43:19.221403Z","iopub.status.idle":"2025-07-11T09:43:19.225997Z","shell.execute_reply.started":"2025-07-11T09:43:19.221380Z","shell.execute_reply":"2025-07-11T09:43:19.225268Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# tokenizer.save(\"/content/tokenizer-wiki.json\")","metadata":{"id":"zFIos9mAwEz3","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:22.380085Z","iopub.execute_input":"2025-07-11T09:43:22.380697Z","iopub.status.idle":"2025-07-11T09:43:22.384022Z","shell.execute_reply.started":"2025-07-11T09:43:22.380674Z","shell.execute_reply":"2025-07-11T09:43:22.383257Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"tokenizer = Tokenizer.from_file(\"/kaggle/input/my-tokenizer/tokenizer-wiki.json\")","metadata":{"id":"yvUzQqtywUIE","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:22.417893Z","iopub.execute_input":"2025-07-11T09:43:22.418111Z","iopub.status.idle":"2025-07-11T09:43:22.473503Z","shell.execute_reply.started":"2025-07-11T09:43:22.418095Z","shell.execute_reply":"2025-07-11T09:43:22.472755Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from tokenizers.processors import TemplateProcessing\ntokenizer.post_processor = TemplateProcessing(\n    single=\"[CLS] $A [SEP]\",\n    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n    special_tokens=[\n        (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n        (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n\n    ],\n)\n\ntokenizer.enable_padding(pad_id=tokenizer.token_to_id(\"[PAD]\"), pad_token=\"[PAD]\",length=350)\ntokenizer.enable_truncation(max_length=350)\n","metadata":{"id":"u4pgViPmwVSD","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:24.096285Z","iopub.execute_input":"2025-07-11T09:43:24.096588Z","iopub.status.idle":"2025-07-11T09:43:24.103909Z","shell.execute_reply.started":"2025-07-11T09:43:24.096566Z","shell.execute_reply":"2025-07-11T09:43:24.103289Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"a5wyOM7un7sv"}},{"cell_type":"code","source":"\nfrom datasets import load_dataset\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\n\nclass NLIDataset(Dataset):\n    def __init__(self, split='test'):\n\n      self.data = load_dataset('sentence-transformers/all-nli', 'pair-class', split=split)\n\n    def __len__(self): return len(self.data)\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        label=item[\"label\"]\n        features=[[item['premise'], item['hypothesis']]]\n\n\n\n        self.features=tokenizer.encode_batch(features)\n        x = torch.tensor([encoding.ids for encoding in self.features], dtype=torch.long)\n        segment_id = torch.tensor([encoding.type_ids for encoding in self.features], dtype=torch.long)\n        mask = torch.tensor([encoding.attention_mask for encoding in self.features], dtype=torch.float)\n\n        return {\"input\":x,\"segment_id\":segment_id,\"mask\":mask,\"label\":torch.tensor(label, dtype=torch.long)}\n\n\n\n","metadata":{"id":"eNOER8WXfppE","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:26.520282Z","iopub.execute_input":"2025-07-11T09:43:26.520577Z","iopub.status.idle":"2025-07-11T09:43:26.526807Z","shell.execute_reply.started":"2025-07-11T09:43:26.520555Z","shell.execute_reply":"2025-07-11T09:43:26.526117Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"dataset = NLIDataset(split='test')\ndata_loader = DataLoader(dataset, batch_size=32, shuffle=True,pin_memory=True)","metadata":{"id":"K9yEsF0iTftp","trusted":true,"execution":{"iopub.status.busy":"2025-07-10T16:10:43.807097Z","iopub.execute_input":"2025-07-10T16:10:43.807996Z","iopub.status.idle":"2025-07-10T16:10:50.697413Z","shell.execute_reply.started":"2025-07-10T16:10:43.807971Z","shell.execute_reply":"2025-07-10T16:10:50.696679Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"035487def5ab4f37ad79aa3b873972f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pair-class/train-00000-of-00001.parquet:   0%|          | 0.00/69.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2543c924e8404209976d5963807b9eb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pair-class/dev-00000-of-00001.parquet:   0%|          | 0.00/1.57M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f1a079c4cb34c14afa0917f1477ce63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pair-class/test-00000-of-00001.parquet:   0%|          | 0.00/1.61M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7eefd86b1ab4582adc8456913707411"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/942069 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e81d92a195ae42f3b41d0009d45edab0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/19657 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f51ca8d667b44f8b4c641e3443cbd72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/19656 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c18053c698e45ad93587862263fc119"}},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Model setup","metadata":{"id":"fm30zBlwm8x6"}},{"cell_type":"code","source":"\nepochs=10\nbatch_size=32\nlr=3e-4 #karpathy_constant\ndevice= \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.backends.cudnn.benchmark = True \nfrom torch.amp import  autocast\nfrom torch.amp import GradScaler\n\n\n\nmodel,classifier=build_transformer(vocab_size,n_segments,embedd_dim,max_len,n_layers,attn_heads,dropout,d_ff,d_ff,True,2)\nmodel=model.to(device)\nclassifier=classifier.to(device)\nscaler=GradScaler()\n\nmodel_optimizer=torch.optim.AdamW(model.parameters(),lr=lr)\ncls_optimizer=torch.optim.AdamW(classifier.parameters(),lr=lr)\nloss_fn=nn.CrossEntropyLoss()\n\n","metadata":{"id":"DVWyecnvmmNb","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:32.542694Z","iopub.execute_input":"2025-07-11T09:43:32.543546Z","iopub.status.idle":"2025-07-11T09:43:36.483994Z","shell.execute_reply.started":"2025-07-11T09:43:32.543519Z","shell.execute_reply":"2025-07-11T09:43:36.483200Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Training Loop","metadata":{"id":"ZCKFGIhypAm3"}},{"cell_type":"code","source":"from tqdm import tqdm\nimport gc\nmodel.train()\nclassifier.train()\nbest_loss=1e9\nfor epoch in range(epochs):\n    train_loss = 0.0\n    correct = 0\n    total = 0\n\n    loop = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n    for batch in loop:\n        x = batch[\"input\"].squeeze(1).to(device)\n        segment_id = batch[\"segment_id\"].squeeze(1).to(device)\n        mask = batch[\"mask\"].squeeze(1).to(device)\n        labels = batch[\"label\"].to(device).unsqueeze(1)  # shape: [B, 1]\n    \n        labels=labels.squeeze(1)\n        with autocast(device):\n            logits = model(x, segment_id, mask)  # shape: [B, 1]\n            logits=classifier(logits)\n            loss = loss_fn(logits, labels)\n\n        model_optimizer.zero_grad()\n        cls_optimizer.zero_grad()\n        scaler.scale(loss).backward()\n    \n        scaler.step(model_optimizer)\n        scaler.step(cls_optimizer)\n        scaler.update()\n        \n\n        train_loss += loss.item()\n\n        # Metrics\n        preds = (torch.argmax(logits,dim=-1)).float()\n        correct += torch.sum((preds == labels).float())\n        total += labels.size(0)\n\n        loop.set_postfix(Loss=loss.item(), Accuracy=(preds==labels).float().mean().item())\n    gc.collect()\n    torch.cuda.empty_cache()\n    avg_loss = train_loss / len(data_loader)\n    torch.save({\"model\":model.state_dict(),\"classifier\":classifier.state_dict()},f\"/kaggle/working/checkpoints_phase1/phase_1_epoch{epoch+1}.pt\")\n    if(avg_loss<best_loss):\n        torch.save({\"model\":model.state_dict(),\"classifier\":classifier.state_dict()},f\"/kaggle/working/checkpoints_phase1/phase_1_best.pt\")\n        best_loss=avg_loss\n    accuracy = correct / total\n    # writer.add_scalar(\"train/loss\",avg_loss,epoch+1)\n    # writer.add_scalar(\"train/accuracy\",accuracy,epoch+1)\n    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n    # global_step += 1\n","metadata":{"id":"XJxTT0W8bJgi","trusted":true,"execution":{"iopub.status.busy":"2025-07-10T16:58:17.421439Z","iopub.execute_input":"2025-07-10T16:58:17.422048Z","iopub.status.idle":"2025-07-10T17:47:21.301348Z","shell.execute_reply.started":"2025-07-10T16:58:17.422024Z","shell.execute_reply":"2025-07-10T17:47:21.300605Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 615/615 [04:53<00:00,  2.09it/s, Accuracy=0.5, Loss=0.983]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Loss: 1.4626, Accuracy: 0.3347\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 615/615 [04:52<00:00,  2.10it/s, Accuracy=0.25, Loss=1.13]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Loss: 1.1322, Accuracy: 0.3543\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 615/615 [04:53<00:00,  2.10it/s, Accuracy=0.375, Loss=1.11] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Loss: 1.0866, Accuracy: 0.4046\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 615/615 [04:53<00:00,  2.09it/s, Accuracy=0.75, Loss=0.884] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Loss: 1.0616, Accuracy: 0.4393\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 615/615 [04:53<00:00,  2.10it/s, Accuracy=0.625, Loss=0.807]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Loss: 1.0203, Accuracy: 0.4894\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 615/615 [04:53<00:00,  2.10it/s, Accuracy=0.25, Loss=1.06]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 - Loss: 0.9818, Accuracy: 0.5320\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 615/615 [04:52<00:00,  2.10it/s, Accuracy=0.625, Loss=1.16] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 - Loss: 0.9266, Accuracy: 0.5677\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 615/615 [04:52<00:00,  2.10it/s, Accuracy=0.375, Loss=0.771]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 - Loss: 0.8845, Accuracy: 0.5957\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 615/615 [04:52<00:00,  2.11it/s, Accuracy=0.75, Loss=0.813] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 - Loss: 0.8510, Accuracy: 0.6166\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 615/615 [04:52<00:00,  2.10it/s, Accuracy=0.75, Loss=0.651] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 - Loss: 0.8158, Accuracy: 0.6396\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"# MNRL Loss","metadata":{"id":"fCM_P8XXgGqA"}},{"cell_type":"code","source":"\nimport torch\nimport torch.nn.functional as F\n\ndef mnr_loss(q_emb: torch.Tensor, p_emb: torch.Tensor, temperature: float = 0.05) -> torch.Tensor:\n    # Normalize embeddings\n    q = F.normalize(q_emb, p=2, dim=1)\n    p = F.normalize(p_emb, p=2, dim=1)\n\n    # Compute cosine similarity matrix: [B, B]\n    logits = torch.matmul(q, p.T) / temperature  # scaled dot product\n\n    # Targets are diagonal (i.e., i-th query matches i-th positive)\n    labels = torch.arange(logits.size(0)).to(logits.device)\n\n    # Cross entropy loss over in-batch negatives\n    return F.cross_entropy(logits, labels)\n","metadata":{"id":"Df5ogxGZgLEc","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:43:53.502345Z","iopub.execute_input":"2025-07-11T09:43:53.503307Z","iopub.status.idle":"2025-07-11T09:43:53.507930Z","shell.execute_reply.started":"2025-07-11T09:43:53.503283Z","shell.execute_reply":"2025-07-11T09:43:53.507171Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import os\n# os.makedirs(\"/kaggle/working/checkpoints_phase1\",exist_ok=True)\nos.makedirs(\"/kaggle/working/checkpoints_phase2\",exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:44:02.191074Z","iopub.execute_input":"2025-07-11T09:44:02.191779Z","iopub.status.idle":"2025-07-11T09:44:02.195163Z","shell.execute_reply.started":"2025-07-11T09:44:02.191758Z","shell.execute_reply":"2025-07-11T09:44:02.194425Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# NQ Dataset","metadata":{"id":"sREvEin2voei"}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom torch.utils.data import Dataset, DataLoader\nclass NQDataset(Dataset):\n  def __init__(self,split=\"train\"):\n    self.ds = load_dataset(\"sentence-transformers/natural-questions\",split=split)\n  def __len__(self):return len(self.ds)\n  def __getitem__(self,idx):\n    item=self.ds[idx]\n    query=item[\"query\"]\n    answer=item[\"answer\"]\n    data=[query]\n    data=tokenizer.encode_batch(data)\n    tokens=torch.tensor([encoding.ids for encoding in data],dtype=torch.long)\n    segment_id=torch.tensor([encoding.type_ids for encoding in data],dtype=torch.long)\n    mask=torch.tensor([encoding.attention_mask for encoding in data],dtype=torch.long)\n\n    passage=tokenizer.encode_batch([answer])\n    passage_tokens=torch.tensor([encoding.ids for encoding in passage],dtype=torch.long)\n    passage_segment_id=torch.tensor([encoding.type_ids for encoding in passage],dtype=torch.long)\n    passage_mask=torch.tensor([encoding.attention_mask for encoding in passage],dtype=torch.long)\n\n    return {\"token\":tokens,\"segment_id\":segment_id,\"mask\":mask,\"passage_token\":passage_tokens,\"passage_segment_id\":passage_segment_id,\"passage_mask\":passage_mask}\n\n\n\n","metadata":{"id":"NHAgVoItGk8U","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:44:06.414876Z","iopub.execute_input":"2025-07-11T09:44:06.415614Z","iopub.status.idle":"2025-07-11T09:44:06.422670Z","shell.execute_reply.started":"2025-07-11T09:44:06.415587Z","shell.execute_reply":"2025-07-11T09:44:06.421705Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"nq_dataset=NQDataset()\nnq_data_loader=DataLoader(nq_dataset,batch_size=32,shuffle=True,pin_memory=True)","metadata":{"id":"BgK6dSFHisZj","trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:44:11.025174Z","iopub.execute_input":"2025-07-11T09:44:11.025728Z","iopub.status.idle":"2025-07-11T09:44:14.410646Z","shell.execute_reply.started":"2025-07-11T09:44:11.025706Z","shell.execute_reply":"2025-07-11T09:44:14.409948Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d45d77e4b7845d29f1e7aa788033d9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pair/train-00000-of-00001.parquet:   0%|          | 0.00/44.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac6db926f17450bb6dffe99acace815"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/100231 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f5260f6e3e488a8705198e16d48ddc"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"check_model=torch.load(\"/kaggle/input/my-tokenizer/phase_2_best (1).pt\")\ncheck_optimizer=torch.load(\"/kaggle/input/my-tokenizer/phase_2_optimizer.pt\")\nmodel.load_state_dict(check_model[\"model\"])\nmodel_optimizer.load_state_dict(check_optimizer[\"optimizer\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:53:11.918573Z","iopub.execute_input":"2025-07-11T09:53:11.919296Z","iopub.status.idle":"2025-07-11T09:53:12.639855Z","shell.execute_reply.started":"2025-07-11T09:53:11.919270Z","shell.execute_reply":"2025-07-11T09:53:12.639144Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# MNRL Training Loop","metadata":{"id":"FFvP-jrRjPx4"}},{"cell_type":"code","source":"from tqdm import tqdm\nimport gc\n\naccum_steps = 2  # Simulate batch size 64 (32 × 2)\nmodel.train()\nbest_loss = 1e9\n# classifier.train()\n\nfor epoch in range(5):\n    train_loss = 0.0\n    loop = tqdm(enumerate(nq_data_loader), total=len(nq_data_loader), desc=f\"Epoch {epoch+1}/10\")\n\n    model_optimizer.zero_grad()  # Important: start clean\n\n    for step, batch in loop:\n        query_token = batch[\"token\"].squeeze(1).to(device)\n        query_segment_id = batch[\"segment_id\"].squeeze(1).to(device)\n        query_mask = batch[\"mask\"].squeeze(1).to(device)\n\n        passage_token = batch[\"passage_token\"].squeeze(1).to(device)\n        passage_segment_id = batch[\"passage_segment_id\"].squeeze(1).to(device)\n        passage_mask = batch[\"passage_mask\"].squeeze(1).to(device)\n\n        with autocast(device):\n            q_emb = model(query_token, query_segment_id, query_mask)\n            p_emb = model(passage_token, passage_segment_id, passage_mask)\n\n            loss = mnr_loss(q_emb, p_emb) / accum_steps  # Normalize loss\n\n        scaler.scale(loss).backward()\n\n        if (step + 1) % accum_steps == 0 or (step + 1) == len(nq_data_loader):\n            scaler.step(model_optimizer)\n            scaler.update()\n            model_optimizer.zero_grad()\n\n        train_loss += loss.item() * accum_steps  # Reverse normalization for logging\n        loop.set_postfix(Loss=loss.item() * accum_steps)\n\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    avg_loss = train_loss / len(nq_data_loader)\n    torch.save({\"model\": model.state_dict()}, f\"/kaggle/working/checkpoints_phase2/phase_2_last.pt\")\n    if avg_loss < best_loss:\n        torch.save({\"model\": model.state_dict()}, f\"/kaggle/working/checkpoints_phase2/phase_2_best.pt\")\n        best_loss = avg_loss\n\n    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T09:53:47.679323Z","iopub.execute_input":"2025-07-11T09:53:47.680059Z","execution_failed":"2025-07-11T13:11:41.995Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 3133/3133 [50:00<00:00,  1.04it/s, Loss=0.628]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Loss: 1.3811\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 3133/3133 [49:55<00:00,  1.05it/s, Loss=1.18] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Loss: 1.3520\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10:  54%|█████▍    | 1696/3133 [27:02<22:50,  1.05it/s, Loss=1.06] ","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Save the model","metadata":{"id":"2s2xhtpGv4P6"}}]}